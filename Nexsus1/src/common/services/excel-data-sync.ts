/**
 * Excel Data Sync Service
 *
 * Syncs data from Excel files to Qdrant vector database.
 * Adapted from Nexsus cascade-sync.ts but uses Excel files instead of Odoo.
 *
 * Data File Convention:
 * - Files: samples/SAMPLE_{model_name}_data.xlsx
 * - Each file contains records for one model
 * - Columns must match schema field names
 *
 * Process Flow:
 * 1. Load schema to get model_id and field definitions
 * 2. Read Excel data file
 * 3. Transform records (generate semantic text)
 * 4. Generate embeddings
 * 5. Upload to Qdrant with V2 UUIDs
 * 6. Optionally cascade to FK targets
 */

import * as path from 'path';
import * as fs from 'fs';
import XLSX from 'xlsx';
import chalk from 'chalk';
import { embedBatch } from './embedding-service.js';
import {
  upsertToUnifiedCollection,
  isVectorClientAvailable,
} from './vector-client.js';
import {
  getModelIdFromSchema,
  getModelFieldsFromSchema,
  modelExistsInSchema,
  getFkFieldsFromSchema,
} from './schema-query-service.js';
import { buildDataUuidV2 } from '../utils/uuid-v2.js';
import { extractFkValueBySchema } from '../utils/fk-value-extractor.js';
import { upsertRelationship } from './knowledge-graph.js';
import { ensureModelIndexes } from './index-service.js';
import { loadSamplePayloadConfig } from './sample-payload-loader.js';
import { registerIndexedFields } from './schema-lookup.js';
import {
  convertValue,
  toUnixTimestamp,
  createConversionStats,
  recordConversion,
  formatConversionStats,
  type ConversionStats,
} from '../utils/type-converter.js';
import type { PipelineDataPoint, PipelineField, RelationshipType } from '../types.js';
import { applyPatternToRecord } from './pattern-service.js';

// =============================================================================
// CONSTANTS
// =============================================================================

/** Default data directory */
const DATA_DIR = process.env.DATA_DIR || 'samples';

/** Batch size for embedding */
const EMBEDDING_BATCH_SIZE = 50;

// =============================================================================
// TYPES
// =============================================================================

/**
 * Options for Excel data sync
 */
export interface ExcelDataSyncOptions {
  /** Custom file path (overrides default naming convention) */
  filePath?: string;
  /** Skip FK cascade (default: false) */
  skipCascade?: boolean;
  /** Dry run - show plan without executing */
  dryRun?: boolean;
  /** Force re-sync even if records exist */
  force?: boolean;
}

/**
 * Result of Excel data sync
 */
export interface ExcelDataSyncResult {
  success: boolean;
  model_name: string;
  model_id: number;
  file_path: string;
  records_read: number;
  records_synced: number;
  records_failed: number;
  duration_ms: number;
  errors: string[];
  cascaded_models?: Array<{
    model_name: string;
    records_synced: number;
  }>;
  /** Type conversion statistics */
  conversionStats?: ConversionStats;
}

/**
 * Transformed record ready for embedding
 */
interface TransformedRecord {
  record_id: number;
  model_name: string;
  model_id: number;
  vector_text: string;
  payload: Record<string, unknown>;
}

// =============================================================================
// HELPER FUNCTIONS
// =============================================================================

/**
 * Get default file path for a model's data file
 */
function getDefaultDataFilePath(modelName: string): string {
  return path.join(DATA_DIR, `SAMPLE_${modelName}_data.xlsx`);
}

/**
 * Read Excel data file
 */
function readExcelData(filePath: string): Array<Record<string, unknown>> {
  if (!fs.existsSync(filePath)) {
    throw new Error(`Data file not found: ${filePath}`);
  }

  const workbook = XLSX.readFile(filePath);
  const sheetName = workbook.SheetNames[0];
  const sheet = workbook.Sheets[sheetName];
  // Use raw: true to prevent XLSX from auto-converting dates (which can cause year offset bugs)
  // We handle date conversion explicitly in type-converter.ts using schema field_type
  const data = XLSX.utils.sheet_to_json(sheet, {
    raw: true,      // Return raw values (numbers for dates, not Date objects)
    defval: null    // Explicit null for empty cells
  });

  return data as Array<Record<string, unknown>>;
}

/**
 * Generate semantic text for a data record
 *
 * Creates human-readable text for vector embedding.
 * Format: "In {model}, record {id}: {field}={value}, {field}={value}, ..."
 */
function generateSemanticText(
  record: Record<string, unknown>,
  modelName: string,
  schemaFields: Array<{ field_name: string; field_label: string; field_type: string }>
): string {
  const parts: string[] = [];

  // Add model context
  parts.push(`In model ${modelName}`);

  // Add record ID
  const recordId = record['id'] as number;
  parts.push(`record ${recordId}`);

  // Add field values (skip id, skip null/undefined)
  for (const field of schemaFields) {
    if (field.field_name === 'id') continue;

    const value = record[field.field_name];
    if (value === null || value === undefined || value === '') continue;

    // Format based on field type (schema-driven)
    let displayValue: string;
    if (field.field_type === 'many2one') {
      // Use schema-driven FK extraction (supports scalar, tuple, and expanded formats)
      const fkResult = extractFkValueBySchema(record, {
        field_id: (field as { field_id?: number }).field_id || 0,
        field_name: field.field_name,
        field_type: field.field_type,
      });

      if (fkResult.fkId !== undefined) {
        if (fkResult.displayName) {
          displayValue = `${fkResult.displayName} (id: ${fkResult.fkId})`;
        } else {
          // For scalar format (Excel), value might be just the ID
          displayValue = `id: ${fkResult.fkId}`;
        }
      } else {
        displayValue = String(value);
      }
    } else if (field.field_type === 'date' || field.field_type === 'datetime') {
      // Schema says this is a date - convert to human-readable ISO format for better embeddings
      // This makes semantic search work better (e.g., "November 2025" matches "2025-11-01")
      const conversion = toUnixTimestamp(value);

      if (conversion.success && conversion.value !== null) {
        const date = new Date(conversion.value as number);
        // Use ISO format for consistent semantic search: "2025-11-01"
        displayValue = date.toISOString().split('T')[0];
      } else {
        displayValue = String(value);
      }
    } else {
      displayValue = String(value);
    }

    parts.push(`${field.field_label || field.field_name} - ${displayValue}`);
  }

  return parts.join(', ');
}

/**
 * Transform Excel records to Qdrant format
 *
 * Uses samples/SAMPLE_payload_config.xlsx to determine which fields
 * should be included in the Qdrant payload.
 *
 * Applies schema-driven type conversion:
 * - date/datetime → Unix timestamp (ms)
 * - integer → number
 * - float/monetary → number
 * - boolean → true/false
 */
async function transformRecords(
  records: Array<Record<string, unknown>>,
  modelName: string,
  modelId: number,
  conversionStats: ConversionStats
): Promise<TransformedRecord[]> {
  // Get schema fields for this model
  const schemaFields = await getModelFieldsFromSchema(modelName);

  if (!schemaFields || schemaFields.length === 0) {
    throw new Error(`No schema fields found for model: ${modelName}`);
  }

  // Load payload config from samples/SAMPLE_payload_config.xlsx
  const payloadConfig = loadSamplePayloadConfig();

  // Filter schema fields to only those with payload=1 in config
  const payloadFields = schemaFields.filter(field => {
    const key = `${modelName}.${field.field_name}`;
    return payloadConfig.get(key)?.include_in_payload === true;
  });

  // Warn if no payload config found for this model (fallback to all fields)
  if (payloadFields.length === 0) {
    console.error(chalk.yellow(
      `[ExcelDataSync] WARNING: No payload config for '${modelName}'. ` +
      `Add to samples/SAMPLE_payload_config.xlsx to control which fields are stored.`
    ));
  } else {
    console.error(chalk.gray(
      `[ExcelDataSync] Using ${payloadFields.length} payload fields from config ` +
      `(out of ${schemaFields.length} total fields)`
    ));
  }

  // Use configured payload fields, or fallback to all schema fields
  const fieldsForPayload = payloadFields.length > 0 ? payloadFields : schemaFields;

  const transformed: TransformedRecord[] = [];

  for (const record of records) {
    const recordId = record['id'] as number;
    if (!recordId) {
      console.error(`[ExcelDataSync] Skipping record without id`);
      continue;
    }

    // Generate semantic text for embedding
    // Try pattern-based narrative first (context-aware), fall back to legacy encoding
    const patternResult = applyPatternToRecord(
      record,
      schemaFields as PipelineField[],
      modelName
    );

    const vectorText = patternResult.applied
      ? patternResult.narrative
      : generateSemanticText(record, modelName, schemaFields);

    // Build payload using ONLY configured payload fields
    // Apply schema-driven type conversion based on field_type
    const payload: Record<string, unknown> = {};
    for (const field of fieldsForPayload) {
      const rawValue = record[field.field_name];

      // Apply type conversion based on schema field_type
      const conversion = convertValue(rawValue, field.field_type, field.field_name);

      // Record conversion in stats
      recordConversion(conversionStats, field.field_type, conversion, field.field_name);

      // Store converted value (null values are not stored in Qdrant payload)
      if (conversion.value !== null && conversion.value !== undefined) {
        payload[field.field_name] = conversion.value;
      }
    }

    // Add FK Qdrant UUIDs for many2one fields in payload (for graph traversal)
    for (const field of fieldsForPayload) {
      if (field.field_type === 'many2one' && field.fk_location_model_id) {
        // Use schema-driven FK extraction (supports scalar, tuple, and expanded formats)
        const fkResult = extractFkValueBySchema(record, {
          field_id: field.field_id || 0,
          field_name: field.field_name,
          field_type: field.field_type,
        });

        if (fkResult.fkId !== undefined) {
          // Build FK Qdrant UUID for graph traversal
          const fkQdrantId = buildDataUuidV2(field.fk_location_model_id, fkResult.fkId);
          payload[`${field.field_name}_qdrant`] = fkQdrantId;

          // Normalize: always store FK ID in _id field for consistent querying
          if (fkResult.source === 'scalar') {
            payload[`${field.field_name}_id`] = fkResult.fkId;
          }
        }
      }
    }

    transformed.push({
      record_id: recordId,
      model_name: modelName,
      model_id: modelId,
      vector_text: vectorText,
      payload,
    });
  }

  return transformed;
}

/**
 * Extract FK targets from records
 *
 * Returns a map of target_model -> Set of record IDs to sync
 */
async function extractFkTargets(
  records: Array<Record<string, unknown>>,
  modelName: string
): Promise<Map<string, Set<number>>> {
  const fkTargets = new Map<string, Set<number>>();

  // Get FK fields for this model from schema
  const fkFields = await getFkFieldsFromSchema(modelName);

  if (!fkFields || fkFields.length === 0) {
    return fkTargets;
  }

  for (const fkField of fkFields) {
    const targetModel = fkField.fk_location_model;
    if (!targetModel) continue;

    // Collect FK IDs from all records
    const targetIds = new Set<number>();

    for (const record of records) {
      // Use schema-driven FK extraction (supports scalar, tuple, and expanded formats)
      const fkResult = extractFkValueBySchema(record, {
        field_id: fkField.field_id || 0,
        field_name: fkField.field_name,
        field_type: fkField.field_type,
      });

      if (fkResult.fkId !== undefined) {
        targetIds.add(fkResult.fkId);
      }
    }

    if (targetIds.size > 0) {
      const existing = fkTargets.get(targetModel) || new Set();
      for (const id of targetIds) {
        existing.add(id);
      }
      fkTargets.set(targetModel, existing);
    }
  }

  return fkTargets;
}

/**
 * Update Knowledge Graph with FK relationships
 *
 * Creates graph edges (point_type='graph') for FK relationships.
 */
async function updateKnowledgeGraph(
  modelName: string,
  modelId: number,
  records: Array<Record<string, unknown>>,
  schemaFields: PipelineField[]
): Promise<{ edges_created: number }> {
  let edgesCreated = 0;

  // Find FK fields (many2one with target model)
  const fkFields = schemaFields.filter(f =>
    f.field_type === 'many2one' && f.fk_location_model && f.fk_location_model_id
  );

  for (const fkField of fkFields) {
    // Collect unique FK IDs from all records (using schema-driven extraction)
    const fkIds = new Set<number>();
    for (const record of records) {
      const fkResult = extractFkValueBySchema(record, {
        field_id: fkField.field_id || 0,
        field_name: fkField.field_name,
        field_type: fkField.field_type,
      });
      if (fkResult.fkId !== undefined) {
        fkIds.add(fkResult.fkId);
      }
    }

    if (fkIds.size > 0) {
      try {
        await upsertRelationship({
          source_model: modelName,
          source_model_id: modelId,
          field_id: fkField.field_id,
          field_name: fkField.field_name,
          field_label: fkField.field_label,
          field_type: fkField.field_type as RelationshipType,
          target_model: fkField.fk_location_model!,
          target_model_id: fkField.fk_location_model_id!,
          edge_count: records.length,
          unique_targets: fkIds.size,
          cascade_source: modelName,
        });
        edgesCreated++;
        console.error(chalk.gray(`[ExcelDataSync] Graph edge: ${modelName}.${fkField.field_name} → ${fkField.fk_location_model}`));
      } catch (error) {
        console.error(chalk.yellow(`[ExcelDataSync] Warning: Failed to create graph edge for ${fkField.field_name}`));
      }
    }
  }

  return { edges_created: edgesCreated };
}

// =============================================================================
// MAIN SYNC FUNCTION
// =============================================================================

/**
 * Sync data from Excel file to Qdrant
 *
 * @param modelName - Model name (e.g., "customer", "country")
 * @param options - Sync options
 * @returns Sync result
 */
export async function syncExcelData(
  modelName: string,
  options: ExcelDataSyncOptions = {}
): Promise<ExcelDataSyncResult> {
  const startTime = Date.now();
  const errors: string[] = [];

  const {
    filePath,
    skipCascade = false,
    dryRun = false,
    force = false,
  } = options;

  console.error(chalk.blue(`\n[ExcelDataSync] Starting sync for model: ${modelName}`));

  // Determine file path
  const dataFilePath = filePath || getDefaultDataFilePath(modelName);
  console.error(chalk.gray(`[ExcelDataSync] Data file: ${dataFilePath}`));

  // Check if model exists in schema
  const modelExists = await modelExistsInSchema(modelName);
  if (!modelExists) {
    const error = `Model '${modelName}' not found in schema. Run schema sync first.`;
    console.error(chalk.red(`[ExcelDataSync] Error: ${error}`));
    return {
      success: false,
      model_name: modelName,
      model_id: 0,
      file_path: dataFilePath,
      records_read: 0,
      records_synced: 0,
      records_failed: 0,
      duration_ms: Date.now() - startTime,
      errors: [error],
    };
  }

  // Get model ID from schema
  const modelId = await getModelIdFromSchema(modelName);
  if (!modelId) {
    const error = `Could not get model ID for: ${modelName}`;
    return {
      success: false,
      model_name: modelName,
      model_id: 0,
      file_path: dataFilePath,
      records_read: 0,
      records_synced: 0,
      records_failed: 0,
      duration_ms: Date.now() - startTime,
      errors: [error],
    };
  }

  console.error(chalk.gray(`[ExcelDataSync] Model ID: ${modelId}`));

  // Read Excel data
  let records: Array<Record<string, unknown>>;
  try {
    records = readExcelData(dataFilePath);
    console.error(chalk.green(`[ExcelDataSync] Read ${records.length} records from Excel`));
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error);
    return {
      success: false,
      model_name: modelName,
      model_id: modelId,
      file_path: dataFilePath,
      records_read: 0,
      records_synced: 0,
      records_failed: 0,
      duration_ms: Date.now() - startTime,
      errors: [errorMsg],
    };
  }

  if (records.length === 0) {
    console.error(chalk.yellow(`[ExcelDataSync] No records found in ${dataFilePath}`));
    return {
      success: true,
      model_name: modelName,
      model_id: modelId,
      file_path: dataFilePath,
      records_read: 0,
      records_synced: 0,
      records_failed: 0,
      duration_ms: Date.now() - startTime,
      errors: [],
    };
  }

  if (dryRun) {
    console.error(chalk.yellow(`[ExcelDataSync] DRY RUN - would sync ${records.length} records`));
    return {
      success: true,
      model_name: modelName,
      model_id: modelId,
      file_path: dataFilePath,
      records_read: records.length,
      records_synced: 0,
      records_failed: 0,
      duration_ms: Date.now() - startTime,
      errors: [],
    };
  }

  // Transform records with schema-driven type conversion
  const conversionStats = createConversionStats();
  const transformed = await transformRecords(records, modelName, modelId, conversionStats);
  console.error(chalk.gray(`[ExcelDataSync] Transformed ${transformed.length} records`));

  // Embed and upload in batches
  let recordsSynced = 0;
  let recordsFailed = 0;

  for (let i = 0; i < transformed.length; i += EMBEDDING_BATCH_SIZE) {
    const batch = transformed.slice(i, i + EMBEDDING_BATCH_SIZE);
    const batchNum = Math.floor(i / EMBEDDING_BATCH_SIZE) + 1;
    const totalBatches = Math.ceil(transformed.length / EMBEDDING_BATCH_SIZE);

    console.error(chalk.gray(`[ExcelDataSync] Processing batch ${batchNum}/${totalBatches}`));

    try {
      // Generate embeddings
      const texts = batch.map(r => r.vector_text);
      const embeddings = await embedBatch(texts, 'document');

      if (embeddings.length !== batch.length) {
        throw new Error(`Embedding count mismatch: ${embeddings.length} vs ${batch.length}`);
      }

      // Build Qdrant points with V2 UUID format
      const points: PipelineDataPoint[] = batch.map((record, idx) => {
        const pointId = buildDataUuidV2(record.model_id, record.record_id);

        return {
          id: pointId,
          vector: embeddings[idx],
          payload: {
            point_id: pointId,
            point_type: 'data' as const,
            record_id: record.record_id,
            model_name: record.model_name,
            model_id: record.model_id,
            vector_text: record.vector_text,
            sync_timestamp: new Date().toISOString(),
            ...record.payload,
          },
        };
      });

      // Upsert to Qdrant
      await upsertToUnifiedCollection(points);
      recordsSynced += batch.length;

    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      errors.push(`Batch ${batchNum} failed: ${errorMsg}`);
      recordsFailed += batch.length;
      console.error(chalk.red(`[ExcelDataSync] Batch ${batchNum} failed: ${errorMsg}`));
    }
  }

  console.error(chalk.green(`[ExcelDataSync] Synced ${recordsSynced} records to Qdrant`));

  // Update knowledge graph with FK relationships
  const schemaFields = await getModelFieldsFromSchema(modelName);
  if (schemaFields && schemaFields.length > 0) {
    const graphResult = await updateKnowledgeGraph(modelName, modelId, records, schemaFields);
    if (graphResult.edges_created > 0) {
      console.error(chalk.green(`[ExcelDataSync] Created ${graphResult.edges_created} graph edges`));
    }

    // Get payload fields from config for index creation
    const payloadConfig = loadSamplePayloadConfig();
    const payloadFields = schemaFields.filter(field => {
      const key = `${modelName}.${field.field_name}`;
      return payloadConfig.get(key)?.include_in_payload === true;
    });

    // Use payload fields for indexing, or fallback to all schema fields
    const fieldsToIndex = payloadFields.length > 0 ? payloadFields : schemaFields;

    // Ensure payload indexes exist for the fields we're actually storing
    const indexResult = await ensureModelIndexes(modelName, fieldsToIndex);
    if (indexResult.created > 0) {
      console.error(chalk.green(
        `[ExcelDataSync] Created ${indexResult.created} indexes for ${fieldsToIndex.length} payload fields`
      ));
    }

    // Register fields for immediate filtering (sync with INDEXED_FIELDS validation registry)
    const indexedFieldNames: string[] = [];
    for (const f of fieldsToIndex) {
      indexedFieldNames.push(f.field_name);
      // For many2one fields, also register the _id and _qdrant variants
      if (f.field_type === 'many2one') {
        indexedFieldNames.push(`${f.field_name}_id`);
        indexedFieldNames.push(`${f.field_name}_qdrant`);
      }
    }
    registerIndexedFields(indexedFieldNames);
  }

  // FK Cascade (if not skipped)
  const cascadedModels: Array<{ model_name: string; records_synced: number }> = [];

  if (!skipCascade) {
    const fkTargets = await extractFkTargets(records, modelName);

    if (fkTargets.size > 0) {
      console.error(chalk.blue(`\n[ExcelDataSync] FK Cascade - ${fkTargets.size} target models`));

      for (const [targetModel, targetIds] of fkTargets) {
        console.error(chalk.gray(`[ExcelDataSync] Cascading to ${targetModel} (${targetIds.size} records)`));

        try {
          // Recursively sync FK target (with skipCascade to prevent infinite loops)
          const cascadeResult = await syncExcelData(targetModel, {
            skipCascade: true, // Prevent infinite cascade
            dryRun,
            force,
          });

          if (cascadeResult.success) {
            cascadedModels.push({
              model_name: targetModel,
              records_synced: cascadeResult.records_synced,
            });
          }
        } catch (error) {
          const errorMsg = error instanceof Error ? error.message : String(error);
          console.error(chalk.yellow(`[ExcelDataSync] Cascade to ${targetModel} failed: ${errorMsg}`));
        }
      }
    }
  }

  const result: ExcelDataSyncResult = {
    success: errors.length === 0,
    model_name: modelName,
    model_id: modelId,
    file_path: dataFilePath,
    records_read: records.length,
    records_synced: recordsSynced,
    records_failed: recordsFailed,
    duration_ms: Date.now() - startTime,
    errors,
    cascaded_models: cascadedModels.length > 0 ? cascadedModels : undefined,
    conversionStats,
  };

  // Summary
  console.error(chalk.blue(`\n[ExcelDataSync] Sync Complete`));
  console.error(chalk.white(`  Model: ${modelName} (id: ${modelId})`));
  console.error(chalk.white(`  File: ${dataFilePath}`));
  console.error(chalk.white(`  Records: ${recordsSynced} synced, ${recordsFailed} failed`));
  console.error(chalk.white(`  Duration: ${result.duration_ms}ms`));

  // Type conversion report
  if (conversionStats.totalFields > 0) {
    console.error(chalk.blue(`\n[ExcelDataSync] Type Conversion Report`));
    console.error(chalk.white(`  Total fields: ${conversionStats.totalFields}`));
    console.error(chalk.green(`  Successful: ${conversionStats.successfulConversions}`));
    if (conversionStats.failedConversions > 0) {
      console.error(chalk.red(`  Failed: ${conversionStats.failedConversions}`));
    }
    if (conversionStats.nullValues > 0) {
      console.error(chalk.gray(`  Null values: ${conversionStats.nullValues}`));
    }

    // Show breakdown by type
    const typesWithConversions = Object.entries(conversionStats.byType)
      .filter(([type]) => ['date', 'datetime', 'integer', 'float', 'monetary', 'boolean'].includes(type));
    if (typesWithConversions.length > 0) {
      console.error(chalk.gray(`  By type:`));
      for (const [type, counts] of typesWithConversions) {
        console.error(chalk.gray(`    ${type}: ${counts.success} ok, ${counts.failed} failed`));
      }
    }

    // Show sample errors
    if (conversionStats.errors.length > 0) {
      console.error(chalk.yellow(`  Sample errors:`));
      for (const err of conversionStats.errors.slice(0, 5)) {
        console.error(chalk.yellow(`    - ${err.field}: "${err.value}" → ${err.error}`));
      }
    }
  }

  if (cascadedModels.length > 0) {
    console.error(chalk.white(`\n  Cascaded:`));
    for (const cm of cascadedModels) {
      console.error(chalk.gray(`    - ${cm.model_name}: ${cm.records_synced} records`));
    }
  }

  return result;
}

/**
 * Sync all data files in the samples directory
 *
 * Finds all SAMPLE_*_data.xlsx files and syncs them.
 */
export async function syncAllExcelData(
  options: ExcelDataSyncOptions = {}
): Promise<ExcelDataSyncResult[]> {
  const results: ExcelDataSyncResult[] = [];

  // Find all data files
  const dataDir = DATA_DIR;
  if (!fs.existsSync(dataDir)) {
    console.error(chalk.red(`[ExcelDataSync] Data directory not found: ${dataDir}`));
    return results;
  }

  const files = fs.readdirSync(dataDir);
  const dataFiles = files.filter(f => f.match(/^SAMPLE_.*_data\.xlsx$/));

  console.error(chalk.blue(`[ExcelDataSync] Found ${dataFiles.length} data files`));

  for (const file of dataFiles) {
    // Extract model name from file name (SAMPLE_{model}_data.xlsx)
    const match = file.match(/^SAMPLE_(.+)_data\.xlsx$/);
    if (!match) continue;

    const modelName = match[1];
    console.error(chalk.blue(`\n${'='.repeat(60)}`));
    console.error(chalk.blue(`Syncing: ${modelName}`));
    console.error(chalk.blue(`${'='.repeat(60)}`));

    const result = await syncExcelData(modelName, {
      ...options,
      skipCascade: true, // Sync each file independently
    });

    results.push(result);
  }

  return results;
}
